---
title: "Week 3 - Homework"
author: "STAT 420, Summer 2021, D. Unger"
date: ''
output:
  pdf_document: default
  html_document: 
    theme: readable
    toc: yes  
urlcolor: cyan
---


# Directions

Students are encouraged to work together on homework. However, sharing, copying or providing any part of a homework solution or code is an infraction of the University's rules on Academic Integrity. Any violation will be punished as severely as possible.

- Be sure to remove this section if you use this `.Rmd` file as a template.
- You may leave the questions in your final document.

***

## Exercise 1 (Using `lm` for Inference)

For this exercise we will use the `cats` dataset from the `MASS` package. You should use `?cats` to learn about the background of this dataset.

**(a)** Fit the following simple linear regression model in `R`. Use heart weight as the response and body weight as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `cat_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses

Null = H_0 : Beta_1 = 0 (Bwt)
Alternate = H_1 : Beta_0 != 0 (Hwt)

- The value of the test statistic

B_1 t value = 16.1193908

- The p-value of the test

B_1 p-value = 6.969045e-34

- A statistical decision at $\alpha = 0.05$

The p-value for B_1 is 6.969045e-34 which is less than 0.05. Therefore we reject the null.

- A conclusion in the context of the problem

Because the null hypothesis was rejected, we have shown that there is a linear relationship between heart weight and body weight.

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

```{r}
library(MASS)
cat_model = lm(Hwt ~ Bwt, data = cats)
summary(cat_model)$coefficients[, "t value"]
summary(cat_model)$coefficients[, "Pr(>|t|)"]
```


**(b)** Calculate a 95% confidence interval for $\beta_1$. Give an interpretation of the interval in the context of the problem.

```{r}
confint(cat_model, parm = "Bwt", level = .95)
```

We are 95% confident that with a 1kg increase in cat Body Weight, the true change in mean of cat Heart Weight is between 3.539343g and 4.528782g.

**(c)** Calculate a 90% confidence interval for $\beta_0$. Give an interpretation of the interval in the context of the problem.

```{r}
confint(cat_model, parm = "(Intercept)", level = .9)
```

We are 90% confident that a cat that has a body weight of 0kg has a mean heart weight between -1.502834 and 0.7895096. This cannot be accurate because a cat cannot have a negative heart weight.

**(d)** Use a 90% confidence interval to estimate the mean heart weight for body weights of 2.1 and 2.8 kilograms. Which of the two intervals is wider? Why?

```{r}
newweights = data.frame(Bwt = c(2.1, 2.8)) 
predict(cat_model, newdata = newweights, interval = c("confidence"), level = .9)
```

We can see that the interval at 2.1kg is wider than at 2.8kg. This is because 2.1kg is further from the mean than 2.8kg.

**(e)** Use a 90% prediction interval to predict the heart weight for body weights of 2.8 and 4.2 kilograms.

```{r}
newweights = data.frame(Bwt = c(2.8, 4.2)) 
predict(cat_model, newdata = newweights, interval = c("prediction"), level = .9)
```

A cat with a body weight of 2.8kg will have a mean heart weight between 8.525541g and 13.35189g 90% of the time. A cat with a body weight of 4.2kg will have a mean heart weight between 14.097100g and 19.07570g 90% of the time.

**(f)** Create a scatterplot of the data. Add the regression line, 95% confidence bands, and 95% prediction bands.

```{r}
Bwt_grid = seq(min(cats$Bwt), max(cats$Bwt), by = 0.01)

Hwt_ci_band = predict(cat_model, newdata = data.frame(Bwt = Bwt_grid), interval = "confidence", level = 0.95)
Hwt_pi_band = predict(cat_model, newdata = data.frame(Bwt = Bwt_grid), interval = "prediction", level = 0.95)

plot(Hwt ~ Bwt, data = cats,
     xlab = "Cat Body Weight (kg)",
     ylab = "Cat Heart Weight (g)",
     main = "Cat Heart Weight versus Body Weight",
     pch = 20,
     cex = 2,
     col = "grey",
     ylim = c(min(Hwt_pi_band), max(Hwt_pi_band)))
abline(cat_model, lwd = 3, col = "darkorange")

lines(Bwt_grid, Hwt_ci_band[, "lwr"], col = "dodgerblue", lwd = 3, lty = 2)
lines(Bwt_grid, Hwt_ci_band[, 'upr'], col = "dodgerblue", lwd = 3, lty = 2)
lines(Bwt_grid, Hwt_pi_band[, "lwr"], col = "dodgerblue", lwd = 3, lty = 3)
lines(Bwt_grid, Hwt_pi_band[, "upr"], col = "dodgerblue", lwd = 3, lty = 3)
```


**(g)** Use a $t$ test to test:

- $H_0: \beta_1 = 4$
- $H_1: \beta_1 \neq 4$

```{r}
new_t = (summary(cat_model)$coefficients["Bwt", "Estimate"] - 4) / summary(cat_model)$coefficients["Bwt", "Std. Error"]
new_p = 2 * pt(abs(new_t), df = length(resid(cat_model)) - 2, lower.tail = FALSE)
new_t
new_p
```

Report the following:

- The value of the test statistic

0.1361084

- The p-value of the test

0.8919283

- A statistical decision at $\alpha = 0.05$

We fail to reject the hypothesis at Beta_1 = 4 because 0.8919283 is greater than 0.05.

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

***

## Exercise 2 (More `lm` for Inference)

For this exercise we will use the `Ozone` dataset from the `mlbench` package. You should use `?Ozone` to learn about the background of this dataset. You may need to install the `mlbench` package. If you do so, do not include code to install the package in your `R` Markdown document.

For simplicity, we will re-perform the data cleaning done in the previous homework.

```{r}
library(mlbench)
data(Ozone, package = "mlbench")
Ozone = Ozone[, c(4, 6, 7, 8)]
colnames(Ozone) = c("ozone", "wind", "humidity", "temp")
Ozone = Ozone[complete.cases(Ozone), ]
```

**(a)** Fit the following simple linear regression model in `R`. Use the ozone measurement as the response and wind speed as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `ozone_wind_model`. Use a $t$ test to test the significance of the regression. Report the following:

```{r}
ozone_wind_model = lm(ozone ~ wind, data = Ozone)
summary(ozone_wind_model)$coefficients[, "t value"]
summary(ozone_wind_model)$coefficients[, "Pr(>|t|)"]
```

- The null and alternative hypotheses

Null = H_0 : Beta_1 = 0 (wind)
Alternate = H_1 : Beta_0 != 0 (ozone)

- The value of the test statistic

-0.2189811

- The p-value of the test

8.267954e-01

- A statistical decision at $\alpha = 0.01$

Because 8.267954e-01 is larger than 0.01, we fail to reject the null hypothesis.

- A conclusion in the context of the problem

There is no relationship between wind speed and ozone levels.

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

**(b)** Fit the following simple linear regression model in `R`. Use the ozone measurement as the response and temperature as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `ozone_temp_model`. Use a $t$ test to test the significance of the regression. Report the following:

```{r}
ozone_temp_model = lm(ozone ~ temp, data = Ozone)
summary(ozone_temp_model)$coefficients[, "t value"]
summary(ozone_temp_model)$coefficients[, "Pr(>|t|)"]
```


- The null and alternative hypotheses

Null = H_0 : Beta_1 = 0 (temperature)
Alternate = H_1 : Beta_0 != 0 (ozone)

- The value of the test statistic

22.84896

- The p-value of the test

8.153764e-71

- A statistical decision at $\alpha = 0.01$

Because 8.153764e-71 is less than 0.01, we reject the null hypothesis.

- A conclusion in the context of the problem

There is a linear relationship between temperature and ozone level.

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

***

## Exercise 3 (Simulating Sampling Distributions)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = -5$
- $\beta_1 = 3.25$
- $\sigma^2 = 16$

We will use samples of size $n = 50$.

**(a)** Simulate this model $2000$ times. Each time use `lm()` to fit a simple linear regression model, then store the value of $\hat{\beta}_0$ and $\hat{\beta}_1$. Set a seed using **your** birthday before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
birthday = 19950419
set.seed(birthday)
n = 50
x = seq(0, 10, length = n)

sim_slr = function(x, beta_0 = 10, beta_1 = 5, sigma = 1) {
  n = length(x)
  epsilon = rnorm(n, mean = 0, sd = sigma)
  y = beta_0 + beta_1 * x + epsilon
  data.frame(predictor = x, response = y)
}

beta_0_hat = rep(1, 2000)
beta_1_hat = rep(1, 2000)

for(i in 1 : 2000){
  simmed = sim_slr(x, -5, 3.25, 4)
  model = lm(response ~ predictor, simmed)
  beta_0_hat[i] = coef(model)[1]
  beta_1_hat[i] = coef(model)[2]
}
```

**(b)** Create a table that summarizes the results of the simulations. The table should have two columns, one for $\hat{\beta}_0$ and one for $\hat{\beta}_1$. The table should have four rows:

- A row for the true expected value given the known values of $x$
- A row for the mean of the simulated values
- A row for the true standard deviation given the known values of $x$
- A row for the standard deviation of the simulated values

```{r}
birthday = 19950419
set.seed(birthday)
n = 50
x = seq(0, 10, length = n)

sim_slr = function(x, beta_0 = 10, beta_1 = 5, sigma = 1) {
  n = length(x)
  epsilon = rnorm(n, mean = 0, sd = sigma)
  y = beta_0 + beta_1 * x + epsilon
  data.frame(predictor = x, response = y)
}

beta_0_hat = rep(1, 2000)
beta_1_hat = rep(1, 2000)

for(i in 1 : 2000){
  simmed = sim_slr(x, -5, 3.25, 4)
  model = lm(response ~ predictor, simmed)
  beta_0_hat[i] = coef(model)[1]
  beta_1_hat[i] = coef(model)[2]
}

Sxx = sum((x - mean(x)) ^ 2)
beta_0_col = c("Expected" = -5, "Mean" = mean(beta_0_hat), "True sd" = 4 * sqrt((1 / 50) + (mean(x) ^ 2 / Sxx)), "Simulated sd" = sd(beta_0_hat))
beta_1_col = c("Expected" = 3.25, "Mean" = mean(beta_1_hat), "True sd" = 4 / (sqrt(Sxx)), "Simulated sd" = sd(beta_1_hat))
table = data.frame(beta_hat_0 = beta_0_col, beta_hat_1 = beta_1_col)
table
```

**(c)** Plot two histograms side-by-side:

- A histogram of your simulated values for $\hat{\beta}_0$. Add the normal curve for the true sampling distribution of $\hat{\beta}_0$.
- A histogram of your simulated values for $\hat{\beta}_1$. Add the normal curve for the true sampling distribution of $\hat{\beta}_1$.

```{r}
Standard_Dev = 4 * sqrt((1 / 50) + (mean(x) ^ 2 / Sxx))

par(mfrow = c(1,2))

hist(beta_0_hat,
     xlab = "Beta_0_Hat",
     ylim = c(0, .4),
     col = "dodgerblue",
     border = "black",
     freq = FALSE,
     main = "")

curve(dnorm(x, mean = -5, sd = Standard_Dev), add = TRUE, lwd = 2, col = "darkorange")

hist(beta_1_hat,
     xlab = "Beta_1_Hat",
     col = "red",
     border = "black",
     freq = FALSE,
     main = "")


curve(dnorm(x, mean = 3.25, sd = 4 / (sqrt(Sxx))), add = TRUE, lwd = 2, col = "dodgerblue")
```


***

## Exercise 4 (Simulating Confidence Intervals)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = 5$
- $\beta_1 = 2$
- $\sigma^2 = 9$

We will use samples of size $n = 25$.

Our goal here is to use simulation to verify that the confidence intervals really do have their stated confidence level. Do **not** use the `confint()` function for this entire exercise.

**(a)** Simulate this model $2500$ times. Each time use `lm()` to fit a simple linear regression model, then store the value of $\hat{\beta}_1$ and $s_e$. Set a seed using **your** birthday before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
birthday = 19950419
set.seed(birthday)
n = 25
x = seq(0, 2.5, length = n)

beta_1_hat = rep(0, 2500)
s_e = rep(0, 2500)

for(i in 1 : 2500){
  simmed = sim_slr(x, 5, 2, 3)
  model = lm(response ~ predictor, data = simmed)
  beta_1_hat[i] = coef(model)[2]
  s_e[i] = summary(model)$coefficients[2, 2]
}
```

**(b)** For each of the $\hat{\beta}_1$ that you simulated, calculate a 95% confidence interval. Store the lower limits in a vector `lower_95` and the upper limits in a vector `upper_95`. Some hints:

- You will need to use `qt()` to calculate the critical value, which will be the same for each interval.
- Remember that `x` is fixed, so $S_{xx}$ will be the same for each interval.
- You could, but do not need to write a `for` loop. Remember vectorized operations.

```{r}
crit_val = qt(0.975, df = 2498)

lower_95 = beta_1_hat - crit_val * s_e
upper_95 = beta_1_hat + crit_val * s_e
```


**(c)** What proportion of these intervals contains the true value of $\beta_1$?

```{r}
confidence_95 = data.frame(2, lower_95, upper_95)

count_95 = 0

for(i in 1 : 2500){
  if(2 >= confidence_95[i, 2]){
    if(2 <= confidence_95[i, 3]){
      count_95 = count_95 + 1
    }
  }
}

count_95 / 2500
```


**(d)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.05$?

```{r}
count_0 = 0

for(i in 1 : 2500){
  if(0 >= confidence_95[i, 2]){
    if(0 <= confidence_95[i, 3]){
      count_0 = count_0 + 1
    }
  }
}

1 - count_0 / 2500

```


**(e)** For each of the $\hat{\beta}_1$ that you simulated, calculate a 99% confidence interval. Store the lower limits in a vector `lower_99` and the upper limits in a vector `upper_99`.

```{r}
crit_val = qt(0.995, df = 2498)

lower_99 = beta_1_hat - crit_val * s_e
upper_99 = beta_1_hat + crit_val * s_e
```


**(f)** What proportion of these intervals contains the true value of $\beta_1$?

```{r}
confidence_99 = data.frame(2, lower_99, upper_99)

count_99 = 0

for(i in 1 : 2500){
  if(2 >= confidence_99[i, 2]){
    if(2 <= confidence_99[i, 3]){
      count_99 = count_99 + 1
    }
  }
}

count_99 / 2500
```

**(g)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.01$?

```{r}
count_0 = 0

for(i in 1 : 2500){
  if(0 >= confidence_99[i, 2]){
    if(0 <= confidence_99[i, 3]){
      count_0 = count_0 + 1
    }
  }
}

1 - count_0 / 2500
```

***

## Exercise 5 (Prediction Intervals "without" `predict`)

Write a function named `calc_pred_int` that performs calculates prediction intervals:

$$
\hat{y}(x) \pm t_{\alpha/2, n - 2} \cdot s_e\sqrt{1 + \frac{1}{n}+\frac{(x-\bar{x})^2}{S_{xx}}}.
$$

for the linear model

$$
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i.
$$

**(a)** Write this function. You may use the `predict()` function, but you may **not** supply a value for the `level` argument of `predict()`. (You can certainly use `predict()` any way you would like in order to check your work.)

The function should take three inputs:

- `model`, a model object that is the result of fitting the SLR model with `lm()`
- `newdata`, a data frame with a single observation (row)
    - This data frame will need to have a variable (column) with the same name as the data used to fit `model`.
- `level`, the level (0.90, 0.95, etc) for the interval with a default value of `0.95`

The function should return a named vector with three elements:

- `estimate`, the midpoint of the interval
- `lower`, the lower bound of the interval
- `upper`, the upper bound of the interval

```{r, eval = TRUE}
calc_pred_int = function(model, newdata, level = 0.95){
  n = length(predict(model))
  x = ((model$model)[2])[,1]
  y = ((model$model)[1])[,1]
  y_predicted = predict(model, newdata = newdata)
  y_fitted = model$fitted.values
  x_predicted = newdata[1,]
  crit_val = qt((1 - (1 - level) / 2), df = n - 2)
  SSE = sum((y - y_fitted) ^ 2)
  s_e = sqrt(SSE / (n-2))
  Sxx = sum((x - mean(x)) ^ 2)

  lower = y_predicted - crit_val * s_e * sqrt(1 + (1 / n) + (x_predicted - mean(x)) ^ 2 / Sxx)
  upper = y_predicted + crit_val * s_e * sqrt(1 + (1 / n) + (x_predicted - mean(x)) ^ 2 / Sxx)
  estimate = y_predicted
  
  intervals = c("estimate" = estimate, "lower" = lower, "upper" = upper)
  intervals
}
```

**(b)** After writing the function, run this code:

```{r, eval = TRUE}
newcat_1 = data.frame(Bwt = 4.0)
calc_pred_int(cat_model, newcat_1)
```
estimate.1    lower.1    upper.1 
  15.77959   12.83018   18.72900
**(c)** After writing the function, run this code:

```{r, eval = TRUE}
newcat_2 = data.frame(Bwt = 3.3)
calc_pred_int(cat_model, newcat_2, level = 0.90)
```
estimate.1    lower.1    upper.1 
  12.95574   10.53099   15.38050

