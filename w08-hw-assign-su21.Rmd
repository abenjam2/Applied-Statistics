---
title: "Week 8 - Homework"
author: "STAT 420, Summer 2021, D. Unger"
date: ''
output:
  html_document: 
    theme: readable
    toc: yes
  pdf_document: default
urlcolor: cyan
---


# Directions

Students are encouraged to work together on homework. However, sharing, copying or providing any part of a homework solution or code is an infraction of the University's rules on Academic Integrity. Any violation will be punished as severely as possible.

- Be sure to remove this section if you use this `.Rmd` file as a template.
- You may leave the questions in your final document.

***

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80, fig.alin = "center")
```

## Exercise 1 (Writing Functions)

**(a)** Write a function named `diagnostics` that takes as input the arguments:

- `model`, an object of class `lm()`, that is a model fit via `lm()`
- `pcol`, for controlling point colors in plots, with a default value of `grey`
- `lcol`, for controlling line colors in plots, with a default value of `dodgerblue`
- `alpha`, the significance level of any test that will be performed inside the function, with a default value of `0.05`
- `plotit`, a logical value for controlling display of plots with default value `TRUE`
- `testit`, a logical value for controlling outputting the results of tests with default value `TRUE`

The function should output:

- A list with two elements when `testit` is `TRUE`:
    - `p_val`, the p-value for the Shapiro-Wilk test for assessing normality
    - `decision`, the decision made when performing the Shapiro-Wilk test using the `alpha` value input to the function. "Reject" if the null hypothesis is rejected, otherwise "Fail to Reject."
- Two plots, side-by-side, when `plotit` is `TRUE`:
    - A fitted versus residuals plot that adds a horizontal line at $y = 0$, and labels the $x$-axis "Fitted" and the $y$-axis "Residuals." The points and line should be colored according to the input arguments. Give the plot a title. 
    - A Normal Q-Q plot of the residuals that adds the appropriate line using `qqline()`. The points and line should be colored according to the input arguments. Be sure the plot has a title. 
```{r}
diagnostics = function(model, pcol = "grey", lcol = "dodgerblue", alpha = 0.05, plotit = TRUE, testit = TRUE){
  if(testit == TRUE){
    p_val = shapiro.test(resid(model))$p.value
    if(alpha > p_val){
      decision = "Reject"
      pdec = list(p_val, decision)
    }
    else{
      decision = "Fail to Reject"
      pdec = list("p_val" = p_val, "decision" = decision)
    }
    print(pdec)
  }
  if(plotit == TRUE){
    par(mfrow = c(1, 2))
    plot(fitted(model), resid(model), col = pcol, pch = 20,
         xlab = "Fitted", ylab = "Residuals", main = "Data from Model")
    abline(h = 0, col = lcol, lwd = 2)
    
    qqnorm(resid(model), main = "Normal Q-Q Plot, model", col = pcol)
    qqline(resid(model), col = lcol, lwd = 2)
  }
}
```


Consider using this function to help with the remainder of the assignment as well.

**(b)** Run the following code.

```{r}
set.seed(40)

data_1 = data.frame(x = runif(n = 30, min = 0, max = 10),
                    y = rep(x = 0, times = 30))
data_1$y = with(data_1, 2 + 1 * x + rexp(n = 30))
fit_1 = lm(y ~ x, data = data_1)

data_2 = data.frame(x = runif(n = 20, min = 0, max = 10),
                    y = rep(x = 0, times = 20))
data_2$y = with(data_2, 5 + 2 * x + rnorm(n = 20))
fit_2 = lm(y ~ x, data = data_2)

data_3 = data.frame(x = runif(n = 40, min = 0, max = 10),
                    y = rep(x = 0, times = 40))
data_3$y = with(data_3, 2 + 1 * x + rnorm(n = 40, sd = x))
fit_3 = lm(y ~ x, data = data_3)
```

```{r, eval = TRUE}
diagnostics(fit_1, plotit = FALSE)$p_val
diagnostics(fit_2, plotit = FALSE)$decision
diagnostics(fit_1, testit = FALSE, pcol = "black", lcol = "black")
diagnostics(fit_2, testit = FALSE, pcol = "grey", lcol = "green")
diagnostics(fit_3)
```

***

## Exercise 2 (Prostate Cancer Data)

For this exercise, we will use the `prostate` data, which can be found in the `faraway` package. After loading the `faraway` package, use `?prostate` to learn about this dataset.

```{r, message = FALSE, warning = FALSE}
library(faraway)
```

**(a)** Fit an additive multiple regression model with `lpsa` as the response and the remaining variables in the `prostate` dataset as predictors. Report the $R^2$ value for this model.

```{r}
model = lm(lpsa ~ ., prostate)
summary(model)$r.squared
```


**(b)** Check the constant variance assumption for this model. Do you feel it has been violated? Justify your answer.

```{r}
plot(fitted(model), resid(model), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Data from Model")
abline(h = 0, col = "darkorange", lwd = 2)
```

Based on the fitted versus residuals plot, it does not look like the constant variance assumption is violated. It appears that at each fitted value, the residuals vary relatively equally.

**(c)** Check the normality assumption for this model. Do you feel it has been violated? Justify your answer.

```{r}
hist(resid(model),
     xlab   = "Residuals",
     main   = "Histogram of Residuals, model",
     col    = "darkorange",
     border = "dodgerblue",
     breaks = 40)
```

Based on the above histogram, it does appear that the normality assumption is violated. There are several peaks in the histogram, rather than having one centered peak.

**(d)** Check for any high leverage observations. Report any observations you determine to have high leverage.

```{r}
x0 = rep(1, 97)
x1 = prostate$lcavol
x2 = prostate$lweight
x3 = prostate$age
x4 = prostate$lbph
x5 = prostate$svi
x6 = prostate$lcp
x7 = prostate$gleason
x8 = prostate$pgg45

X = cbind(x0, x1, x2, x3, x4, x5, x6, x7, x8)

H = X %*% solve(t(X) %*% X) %*% t(X)

diag(H)[diag(H)> 2 * mean(diag(H))]
```

**(e)** Check for any influential observations. Report any observations you determine to be influential.

```{r}
CD = cooks.distance(model)
CD[CD > 4 / length(CD)]
```

**(f)** Refit the additive multiple regression model without any points you identified as influential. Compare the coefficients of this fitted model to the previously fitted model.

```{r}
prostate_sub = prostate[-c(32, 39, 47, 69, 95, 96, 97), ]
model_sub = lm(lpsa ~ ., prostate_sub)
summary(model)
summary(model_sub)
```

The model without the influential points has different intercept values. The standard error for each of the predictors is less as well.

**(g)** Create a data frame that stores the observations that were "removed" because they were influential. Use the two models you have fit to make predictions with these observations. Comment on the difference between these two sets of predictions.

```{r}
prostate_rem = prostate[c(32, 39, 47, 69, 95, 96, 97), ]
predict(model_sub, data.frame(prostate_rem))

predict(model, data.frame(prostate_rem))
```

We can see that the model with the influential points removed predict an lpsa further away from the observed lpsa. The model with the influential points predicts lpsa values closer to the observed lpsa, but still not very close.

***

## Exercise 3 (Why Bother?)

**Why** do we care about violations of assumptions? One key reason is that the distributions of the parameter esimators that we have used are all reliant on these assumptions. When the assumptions are violated, the distributional results are not correct, so our tests are garbage. **Garbage In, Garbage Out!**

Consider the following setup that we will use for the remainder of the exercise. We choose a sample size of 50.

```{r}
n = 50
set.seed(420)
x_1 = runif(n, 0, 5)
x_2 = runif(n, -2, 2)
```

Consider the model,

\[
Y = 4 + 1 x_1 + 0 x_2 + \epsilon.
\]

That is,

- $\beta_0$ = 4
- $\beta_1$ = 1
- $\beta_2$ = 0

We now simulate `y_1` in a manner that does **not** violate any assumptions, which we will verify. In this case $\epsilon \sim N(0, 1).$

```{r}
set.seed(83)
library(lmtest)
y_1 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = 1)
fit_1 = lm(y_1 ~ x_1 + x_2)
bptest(fit_1)
```

Then, we simulate `y_2` in a manner that **does** violate assumptions, which we again verify. In this case $\epsilon \sim N(0, \sigma = |x_2|).$

```{r}
set.seed(83)
y_2 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = abs(x_2))
fit_2 = lm(y_2 ~ x_1 + x_2)
bptest(fit_2)
```

**(a)** Use the following code after changing `birthday` to your birthday.

```{r}
num_sims = 2500
p_val_1 = rep(0, num_sims)
p_val_2 = rep(0, num_sims)
birthday = 19950419
set.seed(birthday)
```

Repeat the above process of generating `y_1` and `y_2` as defined above, and fit models with each as the response `2500` times. Each time, store the p-value for testing,

\[
\beta_2 = 0,
\]

using both models, in the appropriate variables defined above. (You do not need to use a data frame as we have in the past. Although, feel free to modify the code to instead use a data frame.)

```{r}
for(i in 1:num_sims){
  y_1 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = 1)
  fit_1 = lm(y_1 ~ x_1 + x_2)
  y_2 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = abs(x_2))
  fit_2 = lm(y_2 ~ x_1 + x_2)
  p_val_1[i] = summary(fit_1)$coefficients["x_2", "Pr(>|t|)"]
  p_val_2[i] = summary(fit_2)$coefficients["x_2", "Pr(>|t|)"]
}
```


**(b)** What proportion of the `p_val_1` values is less than 0.01? Less than 0.05? Less than 0.10? What proportion of the `p_val_2` values is less than 0.01? Less than 0.05? Less than 0.10? Arrange your results in a table. Briefly explain these results.

```{r}
library(knitr)

p_1_01 = length(p_val_1[p_val_1 < 0.01]) / length(p_val_1)
p_1_05 = length(p_val_1[p_val_1 < 0.05]) / length(p_val_1)
p_1_1 = length(p_val_1[p_val_1 < 0.1]) / length(p_val_1)

p_1 = cbind(p_1_01, p_1_05, p_1_1)

p_2_01 = length(p_val_2[p_val_2 < 0.01]) / length(p_val_2)
p_2_05 = length(p_val_2[p_val_2 < 0.05]) / length(p_val_2)
p_2_1 = length(p_val_2[p_val_2 < 0.1]) / length(p_val_2)

p_2 = cbind(p_2_01, p_2_05, p_2_1)

p = matrix(c(p_1, p_2), ncol = 2)
colnames(p) = c("p_val_1", "p_val_2")
rownames(p) = c("alpha = 0.01", "alpha = 0.05", "alpha = 0.1")
p = as.table(p)
kable(p)
```

We find that the majority of p values are greater than alpha. Because of this, we fail to reject the null hypothesis.

***

## Exercise 4 (Corrosion Data)

For this exercise, we will use the `corrosion` data, which can be found in the `faraway` package. After loading the `faraway` package, use `?corrosion` to learn about this dataset.

```{r, message = FALSE, warning = FALSE}
library(faraway)
```

**(a)** Fit a simple linear regression with `loss` as the response and `Fe` as the predictor. Plot a scatterplot and add the fitted line. Check the assumptions of this model.

```{r}
model = lm(loss ~ Fe, corrosion)
plot(corrosion$Fe, corrosion$loss, xlab = "Iron Content (%)", ylab = "Weight Loss (mg/dm^2 per day)", main = "Weight Loss versus Iron Content")
abline(model, col = "blue")
```

From the above plot, we can see that the data does follow a linear trend. It also appears that the observed data at each Iron Content has an equal variance.

**(b)** Fit higher order polynomial models of degree 2, 3, and 4. For each, plot a fitted versus residuals plot and comment on the constant variance assumption. Based on those plots, which of these three models do you think are acceptable? Use a statistical test(s) to compare the models you just chose. Based on the test, which is preferred? Check the normality assumption of this model. Identify any influential observations of this model.

```{r}
model2 = lm(loss ~ Fe + I(Fe ^ 2), corrosion)
model3 = lm(loss ~ Fe + I(Fe ^ 2) + I(Fe ^ 3), corrosion)
model4 = lm(loss ~ Fe + I(Fe ^ 2) + I(Fe ^ 3) + I(Fe ^ 4), corrosion)

par(mfrow = c(1, 3))

plot(fitted(model2), resid(model2), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Data from Model 2")
abline(h = 0, col = "darkorange", lwd = 2)

plot(fitted(model3), resid(model3), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Data from Model 3")
abline(h = 0, col = "darkorange", lwd = 2)

plot(fitted(model4), resid(model4), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Data from Model 4")
abline(h = 0, col = "darkorange", lwd = 2)

anova(model4, model3)
anova(model3, model2)
anova(model2, model)

shapiro.test(resid(model3))

cooks.distance(model3)[cooks.distance(model3) > 4 / length(cooks.distance(model3))]

```

From the above fitted versus residuals plots, we can see that the model of degree 3 appears to be the only one that does not violate linearity or equal variance. From the anova tests, it can be seen that model 4 is not preferred over model 3. However, model 3 is preferred over model 2. Therefore, model 3 (of degree 3) is the preferred model.

From the Shapiro-Wilk Test, we can see that the model of degree 3 has a high p-value. This means that the data is sampled from the normal.

From the Cook's Distance Test, we can see that none of the observations are influential.

***

## Exercise 5 (Diamonds)

The data set `diamonds` from the `ggplot2` package contains prices and characteristics of 54,000 diamonds. For this exercise, use `price` as the response variable $y$, and `carat` as the predictor $x$. Use `?diamonds` to learn more.

```{r, message = FALSE, warning = FALSE}
library(ggplot2)
```

**(a)** Fit a linear model with `price` as the response variable $y$, and `carat` as the predictor $x$. Return the summary information of this model.

```{r}
model = lm(price ~ carat, diamonds)
summary(model)
```

**(b)** Plot a scatterplot of price versus carat and add the line for the fitted model in part **(a)**. Using a fitted versus residuals plot and/or a Q-Q plot, comment on the diagnostics. 

```{r}
par(mfrow = c(1, 3))

plot(diamonds$carat, diamonds$price, xlab = "Carat", ylab = "Price ($)", main = "Price versus Carat", col = "darkgrey")
abline(model, lwd = 2, col = "dodgerblue")

plot(fitted(model), resid(model), xlab = "Fitted", ylab = "Residuals", main = "Residuals versus Fitted", col = "darkgrey")
abline(h = 0, lwd = 2, col = "dodgerblue")

qqnorm(resid(model), main = "Normal Q-Q Plot", col = "darkgrey")
qqline(resid(model), col = "dodgerblue", lwd = 2)
```


From the Price versus Carat plot, it appears that the data doesn't accurately follow a linear model. From the Residuals versus Fitted plot, we notice that there is not equal variance among the residuals. Lastly, with the Q-Q plot, we notice that there are fat tails. Because of this, we know that it is not a normal distribution.

**(c)** Seeing as the price stretches over several orders of magnitude, it seems reasonable to try a log transformation of the response. Fit a model with a logged response, plot a scatterplot of log-price versus carat and add the line for the fitted model, then use a fitted versus residuals plot and/or a Q-Q plot to comment on the diagnostics of the model.

```{r}
qplot(price, data = diamonds, bins = 30)
```

```{r}
log_model = lm(log(price) ~ carat, diamonds)

par(mfrow = c(1, 3))

plot(log(price) ~ carat, data = diamonds, xlab = "log(Carat)", ylab = "Price ($)", main = "Price versus Carat", col = "darkgrey")
abline(log_model, lwd = 2, col = "dodgerblue")

plot(fitted(log_model), resid(log_model), xlab = "Fitted", ylab = "Residuals", main = "Residuals versus Fitted", col = "darkgrey")
abline(h = 0, lwd = 2, col = "dodgerblue")

qqnorm(resid(log_model), main = "Normal Q-Q Plot", col = "darkgrey")
qqline(resid(log_model), col = "dodgerblue", lwd = 2)

```

We can see from the log(Price) versus Carat plot that the model better fits the data. However, it is still not an accurate fit. The log transformation on the response did not help much with the Residuals versus Fitted plot, however. Lastly, the log transformation on the response fixed the fat tail on the higher quantiles in the Q-Q plot. However, the fat tail remains on the lower quantiles.

**(d)** Try adding log transformation of the predictor. Fit a model with a logged response and logged predictor, plot a scatterplot of log-price versus log-carat and add the line for the fitted model, then use a fitted versus residuals plot and/or a Q-Q plot to comment on the diagnostics of the model.

```{r}
log2_model = lm(log(price) ~ log(carat), diamonds)

par(mfrow = c(1, 3))

plot(log(price) ~ log(carat), data = diamonds, xlab = "log(Carat)", ylab = "log(Price)", main = "log(Price) versus log(Carat)", col = "darkgrey")
abline(log2_model, lwd = 2, col = "dodgerblue")

plot(fitted(log2_model), resid(log2_model), xlab = "Fitted", ylab = "Residuals", main = "Residuals versus Fitted", col = "darkgrey")
abline(h = 0, lwd = 2, col = "dodgerblue")

qqnorm(resid(log2_model), main = "Normal Q-Q Plot", col = "darkgrey")
qqline(resid(log2_model), col = "dodgerblue", lwd = 2)
```

This model meets the assumptions. From the log(Price) versus log(Carat) plot, we can see that the data follows the linear model well. From the Residuals versus Fitted plot, the residuals are centered around 0 (proving linearity) and have equal variance at each fitted value. From the Q-Q Plot, we can see that there are no more fat tails, meaning that the data follows a normal distribution.

**(e)** Use the model from part **(d)** to predict the price (in dollars) of a 3-carat diamond. Construct a 99% prediction interval for the price (in dollars).

```{r}
exp(predict(log2_model, data.frame(carat = log(3)), interval="prediction", level=.99))
```


